\begin{figure}
	\centering
		\includegraphics[scale=.45]{figs/The_proposed_model_workflow.jpeg}
	\caption{The proposed model workflow}
	\label{model_workflow}
\end{figure}


{\verb|hypothesis|}


\begin{enumerate}
\item[$\bullet$] Recipe A ingredients are: 300g chicken, 60g cheese, 100g potatoes
\item[$\bullet$] Recipe B ingredients are: 100g chicken, 120g cheese, 100g potatoes
\end{enumerate}


\begin{verbatim}
 \newtheorem{theorem}{Theorem}
 \newtheorem{lemma}[theorem]{Lemma}
 \newdefinition{rmk}{Remark}
 \newproof{pf}{Proof}
 \newproof{pot}{Proof of Theorem \ref{thm2}}
\end{verbatim}


\newtheorem{theorem}{Theorem}

\begin{theorem}
For system (8), consensus can be achieved with 
$\|T_{\omega z}$ ...
\begin{eqnarray}\label{10}
....
\end{eqnarray}
\end{theorem}


\begin{verbatim}
 \begin{enumerate}[Step 1.]
  \item This is the first step of the example list.
  \item Obviously this is the second step.
  \item The final step to wind up this example.
 \end{enumerate}
\end{verbatim}






%reference

%[3]
@article{goldberg2017neural,
  title={Neural network methods for natural language processing},
  author={Goldberg, Yoav},
  journal={Synthesis lectures on human language technologies},
  volume={10},
  number={1},
  pages={1--309},
  year={2017},
  publisher={Morgan \& Claypool Publishers}
}

%[4]
@article{bengio2003neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of machine learning research},
  volume={3},
  number={Feb},
  pages={1137--1155},
  year={2003}
}


%[5]
@inproceedings{mikolov2011extensions,
  title={Extensions of recurrent neural network language model},
  author={Mikolov, Tom{\'a}{\v{s}} and Kombrink, Stefan and Burget, Luk{\'a}{\v{s}} and {\v{C}}ernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle={2011 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5528--5531},
  year={2011},
  organization={IEEE}
}

%[6]
@inproceedings{sundermeyer2012lstm,
  title={LSTM neural networks for language modeling},
  author={Sundermeyer, Martin and Schl{\"u}ter, Ralf and Ney, Hermann},
  booktitle={Thirteenth annual conference of the international speech communication association},
  year={2012}
}

%[7]
@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}






















